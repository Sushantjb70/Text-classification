
# Text-classification
Text classification using various feature engineering methods and applying various algorithms like logistic, SVM, Bagging and Boosting methods adn also with Neural networks.

# Steps
<pre>
1. Dataset Preparation: The first step is the Dataset Preparation step which includes the process of loading a dataset and performing basic pre-processing. The dataset is then splitted into train and validation sets.
2. Feature Engineering: The next step is the Feature Engineering in which the raw dataset is transformed into flat features which can be used in a machine learning model. This step also includes the process of creating new features from the existing data.
3. Model Training: The final step is the Model Building step in which a machine learning model is trained on a labelled dataset.
</pre>

# We will use the following methods for feature engineering:
<pre>
1 Count Vectors as features <br />
2 TF-IDF Vectors as features <br />
  2.1 Word level <br />
  2.2 N-Gram level <br />
  2.3 Character level <br />
3 Word Embeddings as features <br />
4 Text / NLP based features <br />
5 Topic Models as features <br />
</pre>

# We will use the following classifiers:
<pre>
1 Naive Bayes Classifier <br />
2 Linear Classifier <br />
3 Support Vector Machine <br />
4 Bagging Models <br />
5 Boosting Models <br />
6 Shallow Neural Networks <br />
7 Convolutional Neural Network (CNN) <br />
8 Long Short Term Modelr (LSTM) <br />
9 Gated Recurrent Unit (GRU) <br />
10 Bidirectional RNN <br />
11 Recurrent Convolutional Neural Network (RCNN) <br />
</pre>
The data is in corpus1.txt file.The data contains amazon reviews.

